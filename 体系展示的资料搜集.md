# 体系展示的资料搜集

## Victim cache 的介绍（感性理解）
Victim cache（受害者缓存）是计算机体系结构中的一种缓存优化技术，用于提高缓存命中率和减少访问主存的延迟。

在传统的缓存系统中，被替换掉的块会被写回主存，被新的块代替。而有了受害者缓存，这些被驱逐出去的块就会被存在这个小缓存中，等待着下一次被召唤（也可能没被召唤，下场就是被踢回 Memory 中了）。

这块受害者缓存通常是全相联的（Fully Associative），并且有着非常少的 Entries（通常 4 ~ 16 个）（类似block 的概念）。在多级缓存系统中，受害者缓存通常放置在 L1 缓存旁，两个缓存可以进行并行访问（Parallel Checking），或者按序访问（Series Checking）。

1. 检查 L1 Cache；如果命中，那么返回数据
2. 如果没有命中，那么检查 Victim Cache（假设是按序检查Series Checking）。如果 Victim Cache 里面有这个数据，那么该数据将会返回给 L1 Cache 然后再送还给处理器。在 L1 Cache 里被驱逐的数据，会存放进 Victim Cache 里面
3. 如果 L1 Cache 和 Victim Cache 都没有该数据，那么就会从 Memory/L2 Cache 取出该数据，并把它放在 L1 Cache 里面。如果在该次操作里面，L1 Cache 需要驱逐一个数据，那么这个被驱逐的数据会被存进 Victim Cache 里面。任何被 Victim Cache 驱逐的未修改过的数据，都会写进 Memory 里面或者被丢弃

## 技术提出时面临的问题
在 victim cache 提出之前出现了一系列问题，已有的技术（miss cache 即未命中缓存，之后会介绍它的功能）也存在一定缺陷。

### 流水线的广泛使用造成性能严重下降
缓存未命中时，处理器需访问主存，导致流水线停顿。流水线级数越多（如 10 级 vs. 5 级），未命中导致的停顿会传播到更多后续阶段。例如若主存访问需 100 个周期，五级流水线需停顿 100×5=500 个指令周期。十级流水线则需停顿 100×10=1000 个指令周期。

当数据未命中时，处理器可能需清空流水线中依赖该数据的指令，进一步加剧性能损失。

高流水线处理器通常支持每周期发射多条指令（如 4 条）。若数据未命中导致流水线停顿，这些并行指令的资源（如执行单元、寄存器）将被闲置。

流水线越深，分支预测错误时需回滚的指令数越多（如 10 级流水线需回滚 9 条指令）。

### 处理器的速度远超主存的访问速度

处理器的时钟周期时间（Cycle Time）以远超主存访问时间的速度缩短。


### 指令集的升级
  
由于 RISC 等指令集的出现，一条指令的 CPI 通常较低，因此缓存未命中的停顿会导致整体性能下降。


### 实例
VAX 11/780 处理器的缓存未命中仅消耗平均指令执行时间的 60%，即使所有指令均发生缓存未命中，机器性能也仅下降约 40%。然而，对于流水线深度更深的现代处理器（如 WRT Titan），缓存未命中的代价已飙升至平均指令时间的 8.6 倍。若未来处理器的主频进一步提升（如 0.5 周期 / 指令），主存访问延迟可能超过 100 个指令周期，导致超过半数的潜在性能因内存层级的瓶颈而损失。
（图片见论文table 1-1）

### 解决方案

受害者缓存是对未命中缓存（介绍详见后文，是一种类似victim cache 的技术）的改进，它存入的数据不是从主存中取出的数据而是主存丢出的数据。仅包含 1-5 个entry 的受害者缓存比未命中缓存更能有效减少冲突未命中。


### 分析问题

本部分意在通过实验分析得出制约存储器性能的主要因素在于 L1 cache 未命中。如果需要大量数据的话 L2 cache 命中率也会成为影响因素。但是这个是使用文中另外一个技术解决的，这里不赘述。

#### 基础架构

见论文图2-1

##### 一级缓存

4KB 大小，

block size 为 16B，

直接映射（即一路组相联），

访问延迟为 1 个 clock cycle。

miss后额外时间开销(miss penalties)  24

##### 二级缓存

512KB-16MB，（这里使用 1MB）

block size 为 128B - 256B, 

直接映射，

访问延迟为 4-30 个 clock cycle。

miss后额外时间开销（miss penalties）  320 

##### 主存

容量：512MB-4GB，由约 1000 片 DRAM 组成。

访问延迟：约 10 倍于二级缓存（因信号传播和 DRAM 时序限制）。


块大小：128B/256B，通过增大预取量缓解主存延迟。

#### 测试代码
|程序名 |	动态指令数	|数据引用数|	总引用数|	程序类型|
|-------|-------------|----------|--------|--------|
|ccom|	31.5M	|14.0M|	45.5M	|C 编译器|
|grr|	134.2M|	59.2M	|193.4M	|PC 板 CAD 工具|
|yacc|	51.0M|	16.7M	|67.7M	|Unix 工具|
|met|	99.4M|	50.3M	|149.7M	|PC 板 CAD 工具|
|linpack|	144.8M	|40.7M|	185.5M|	数值计算（100×100 矩阵）|
|liver|	23.6M|	7.4M|	31.0M|	LFK 数值基准测试|



|程序名 |	缓存未命中率|数据未命中率|
|-------|-------------|----------|
|ccom|9.6%|12%|
|grr|6.1%|6.2%|
|yacc|2.8%|4%|
|met|1.7%|3.9%|
|linpack|0%|14.4%|
|liver|0%|27.3%|

#### 测试结果

##### 原因分析
一级缓存未命中主要导致指令流水线停顿。

二级缓存未命中因程序规模超过缓存容量（如 linpack 的大矩阵运算）。

##### 结果分析

图 2-2 表明（见论文），大多数基准测试因 L1 cache miss 损失超过 50% 的潜在性能，除了一些对数据量要求很高的代码。

**注意，图片中的损失性能应该是标出的面积而不是线。**

因此主要需要解决的两个问题：

1. 如何减少 L1 cache miss 损失？
2. 如何提升 L2 cache 命中率？

Victim Cache 就是为了解决 L1 cache miss 提出的。

## 解决方案 Victim Cache
### 解决问题
缓存未命中可分为强制未命中、容量未命中和冲突未命中。

强制未命中是指第一次访问一个块时发生的未命中，这种未命中无法避免。

容量未命中是由于缓存容量不足以容纳所有需要的数据而产生的。

冲突未命中则是在直接映射或组相联缓存中，当不同的块映射到相同的缓存位置时发生的。根据文献，这种冲突占 40%

在原论文中主要是为了解决直接映射的 L1 Cache 命中率低的问题。

### 思路来源

#### 已有设计——未命中缓存
未命中缓存是一个小型的全相联缓存，当 L1 Cache 发生未命中时，会首先检查未命中缓存中是否包含所需的块。如果包含，那么该块可以在一个周期内从未命中缓存中取出并放入直接映射缓存，从而避免了从下一级存储（如二级缓存或主存）中获取数据的长延迟。

未命中缓存中的数据来源是 L1 Cache 未命中时取数据的时候取两份数据一份存入 L1 Cache 另一份放入未命中缓存。使用 LRU 算法来淘汰数据。

未命中缓存的定位是捕捉近期未命中但可能很快被再次访问的数据。因此可以在 L1 Cache 相连度较低的情况下，减少 L1 Cache 未命中。

正如论文图 3-3 体现的一样，未命中缓存对于数据冲突的处理效果远远好于指令冲突，未命中缓存依赖于时间局部性（即近期被访问的数据可能再次被访问），但对于空间局部性差的程序（如随机访问或长距离跳跃访问），未命中缓存的命中率会迅速下降。例如：
指令冲突常发生在不同进程调用中（通常指令隔得又多又远），未命中缓存无法存储所有可能冲突的指令块。
数据访问若跨越多个不相关的区域，未命中缓存难以捕获所有冲突块。




#### 未命中缓存的问题

当直接映射缓存未命中，且未命中缓存也没有所需数据时，数据会从下一级存储（如二级缓存或主存）被加载进来，然后同时存入直接映射缓存和未命中缓存。这样一来，同一份数据就会在两个缓存中都存在，造成了数据的重复存储。最少可能只有 1 个（所有条目映射到直接映射缓存的同一行时），最多可能是全部（在连续未命中且未命中缓存也未命中的情况下）。

未命中缓存的容量通常较小，一般只有 2 - 5 个条目。当出现数据重复存储时，有限的缓存空间被浪费，使得未命中缓存无法充分发挥其作用。原本可以用来存储更多不同数据块的空间，被重复的数据占用，导致未命中缓存能够覆盖的不同数据块数量减少，从而降低了缓存的命中率。例如，在一个有 4 个条目的未命中缓存中，如果有 2 个条目存储了重复的数据，那么实际上只有 2 个条目可以用来存储其他可能有用的数据块，这大大限制了未命中缓存捕获冲突未命中数据的能力。

### 解决方案——Victim Cache

发生未命中时，我们不再将主存中的数据加载到未命中缓存，而是加载 L1 Cache 被替换的数据。这样就产生了 Victim Cache。

当直接映射缓存未命中但受害者缓存命中时，直接映射缓存行和匹配的受害者缓存行将进行交换。

受害者缓存采用 LRU（最久未使用）替换策略，仅存储被直接映射缓存淘汰的行。

受害者缓存相对于未命中缓存的改进程度取决于未命中缓存中的重复数据量。实验表明，受害者缓存始终优于未命中缓存。

假设一个指令引用流在内部循环中调用了一个与循环体冲突的小程序。若过程与循环体之间的冲突行数超过未命中缓存容量，未命中缓存将无法发挥作用，因为循环开始时的未命中会被后续未命中覆盖。但若使用受害者缓存，循环中可捕获的冲突数量将比未命中缓存翻倍：
- 一组冲突指令存储在直接映射缓存中。
- 另一组冲突指令存储在受害者缓存中。
随着循环执行和过程调用，这些条目将交替被访问。


简要示例见：[受害者缓存（Victim Cache）](https://zhuanlan.zhihu.com/p/700363736)


### 测试
>victim cache 与 L1 Cache 大小比例是什么的时候，优化效果最好

L1 Cache 容量越小，收益越大


L1 Cache block size 越大，收益越大

在 Victim Cache 大小从1到15的时候，越大收益越大。


## 缺点

### 老生常谈的性能问题
牺牲缓存虽然可以减少错失率和错失成本，但会给硬件带了一些新的挑战。如果我们把它和 L1 缓存设计成并行访问，那么硬件复杂度和功耗都会上升；如果设计出按序访问，那么缓存系统整体的延迟就会增加，毕竟多了一个访问步骤。

### 受害者缓存破坏缓存层次包含性属性

在多级缓存层次结构中，**包含性属性（Inclusion Property）** 要求所有低级缓存（如一级缓存 L1）中的数据必须存在于高级缓存（如二级缓存 L2）中。

这一属性的核心作用是确保数据一致性和简化缓存管理（如写策略、无效化操作）。

但是受害者缓存可能破坏包含性属性的场景如下：
一级缓存替换块 A ， 块 A 被存入受害者缓存。
二级缓存中块 A 已被替换或淘汰 ， 此时受害者缓存中的块 A 不在二级缓存中。
包含性违反：一级缓存的受害者缓存包含块 A，但二级缓存中没有块 A。

若受害者缓存中的块未被写入 L2，可能导致处理器从受害者缓存读取旧数据，而 L2 中的数据已更新。

写策略（如写回、写直达）和无效化操作需额外处理受害者缓存的数据。

若受害者缓存中的块在 L2 中缺失，访问时需从主存加载，增加延迟。

## 未来研究

### 对于产业界使用的较大缓存的效果
[Hal Wasserman,Victim-Caching for Large Caches and Modern Workloads ](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=1549f3b4324d7ce2e72040ea506bc81a393f4653)

#### 实验结果
Victim 缓存通过减少冲突未命中提升性能，尤其对中等大小缓存性价比高，且在指令缓存中效果优于数据缓存。


64KB 主缓存中 Victim 缓存效果减弱的核心原因是：冲突未命中比例减少，容量未命中主导，且程序访问模式导致 Victim 缓存无法有效捕获被替换的块。尽管按比例扩展 Victim 缓存容量，但收益被主缓存增大带来的结构性变化（如冲突减少、工作集增大）所抵消。
##### 32KB 主缓存效果
冲突未命中减少：平均减少 35-50% 的总未命中（如 go 程序从 4.42% 降至 1.42%）。
性能 - 面积比：1-2KB Victim 缓存最优，超过此容量后收益递减。
##### 64KB 主缓存效果
效果下降：部分程序（如 vortex）未命中率改善有限，Victim 缓存扩展至 16KB 仍无法达到 32KB 主缓存的优化效果。
##### 指令缓存 vs 数据缓存
指令缓存更优：32KB 指令缓存中，Victim 缓存减少未命中的比例更高（如 m88ksim 从 0.50% 降至 0.04%）。


## 工业界应用

Intel 在 Alder Lake 架构中优化了 Victim Cache 的设计，通过动态调整缓存替换策略，减少高频数据块的冲突未命中。例如，L1 数据缓存（L1D）结合 Victim Cache 后，在科学计算和实时渲染场景中命中率提升约 15%。



Arm Zen 3 及后续架构通过 Victim Cache 缓解 L3 缓存的冲突问题。例如，在 Ryzen 5000 系列中，Victim Cache 与 “Infinity Cache” 协同工作，提升多线程负载下的缓存利用率。


## 参考资料
### 基础知识
- [cache基础与Victim Cache和CAM](https://blog.csdn.net/cy413026/article/details/123139530)
- [Computer Architecture —— Advanced Cache 高级缓存优化（三）](https://zhuanlan.zhihu.com/p/388751723)
- [wiki 受害者缓存](https://en.wikipedia.org/wiki/Victim_cache#cite_note-3)

### 实现论文
- Jouppi, N. P. (1990-05-01). Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers. 17th Annual International Symposium on Computer Architecture, 1990. Proceedings. pp. 364–373. doi:[10.1109/ISCA.1990.134547](https://ieeexplore.ieee.org/document/134547)


### 实验参数
- Hill, Mark D. Aspects ofCache Memory and Instruction Buffer Performance. Ph.D. Th., University of Califomia,Berkeley,1987 [No. UCB/CSD-87-381](https://www2.eecs.berkeley.edu/Pubs/TechRpts/1987/5701.html)

### 未来发展